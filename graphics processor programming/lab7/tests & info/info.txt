Виды параллельности:
1) На уровне задач (разные приложухи на компе на разных ядрах)
2) На уровне данных (как в 1 лр)
3) На уровне алгоритмов
4) На уровне инструкций (низкоуровневый вид на процессоре)

Полновесные процессы: 
Свои адресны пространства, fork(), MPI

Легковесные процессы:
Нет своих областей памяти, есть стек: pthreads, OpenMP, CUDA

Ускорение S = T1/Tn, T1 - время работы на 1 процессоре, Tn - время работы на n процессорах
Коэффициент распараллеливания P = S/N, N - кол-во процессоров
Показывает насколько эффективно было распараллеливание. В идеале = 1

Масшабирование сильное - на фикс наборе данных увеличиваем кол-во процессоров и P остаётся высоким
Масшабирование слабое - увеличиваем выходные данные и кол-во процессоров, легче сохранить P высоким

Закон Амдала: если 1/N вычислений не распараллелено, то ускориться в N раз не получится.
S <= 1/(F+(1-F)/N)
F -кол-во вычислений, которые нельзя распараллелить.
Тогда (T1 - T1 * F) / N + T1 * F - время работы программы на N проц.
T1 / ((T1 - T1 * F)) / N + T1 * F)
1 / (((1 - F) / N + F) * N))
1 / (1 + F * (N - 1))

Эффективность вычислительных систем:
1) Критерий эффективности процессора - флопсы
    Быстродействие:
        1) Пиковое (обычно не достигается)
        2) Линпаковское (# метод Гаусса)
        3) Реальное

2) Критерий эффективности сети - производительность:
    Время передачи данных X со скоростью = S:
    T = X/S + L - по сути латентность

----------------------------------------------------------------------------------------------------
MPI - Message Passing Interface

Чтобы делать параллельные вычисления нужно:
1) распределять вычислительную нагрузку
2) организовать взаимодействие между процессорами

Концепции:

1) Тип операции передачи данных
    a) point to point от одной машины к другой
    b) collective все передают всем или одна всем или все одной

2) Тип данных, пересылаемых в сообщении
Необходимо указывать тип данных при пересылке
Есть возможность создания производных типов данных

3) Понятие коммуникатора (группы процессов)
Обязателен, обмен данными в рамках одного коммуникатора
MPI_COMM_WORLD все процессы там по умолчанию

4) Понятие виртуальной топологии
По сути виртуальное объединение процессов в некоторую сеть в виде решётки произвольной размерности.
    ^
    |
->x y x x->
  y x y x 
  x y x x 
  x x x x
    ^
    |
Каждый процесс может общаться только с соседними
Может быть замыкание

MPI_Init() - передаём аргументы нашей программы
MPI_Comm_size - передаёт кол-во процессов
MPI_Comm_rank - по сути определение номера процесса (как threadId.x в куде) if rank = 0 - рут процесс
MPI_Send - функция для передачи данных от процесса к процессу
MPI_Bcast - отправляет данные все процессам
MPI_Recv - функция для приёма сообщения MPI_ANY_SOURCE MPI_ANY_TAG Это блокирующая операция
status.MPI_SOURCE - указывает ранг отправителя
status.MPI_TAG - тег принятого сообщения
MPI_Get_count - показывает сколько переменных было в сообщении
MPI_Barrier - функция для синхронизации данных
MPI_Finalize() -завершает общение между процессами и программу